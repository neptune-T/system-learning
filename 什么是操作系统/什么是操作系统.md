## 什么是操作系统

我一直认为大学所学的所有的课程没有任何形式上的区别

就比如说，我在学习高数，积分，微分，中值定理，曲率，旋度散度…在当时上这些课程的时候本人真的不清楚这些东西有什么用处，以至于有些课程并没有打算认真去听，在期末考试之前，去了解具体算法，刷足够多的题目可保证自己通关。并没有对这些东西的底层核心或者是它能干什么深入研究，我想大多数的大学生在自己学业之余也不会去探索这些东西，仅仅是上课也只是在听老师讲解这几个公式在$x=0$的时候不能使用这样的知识点。

庆幸的事也在于我没有听过老师的讲解，没有让我对这个知识点有过玷污，它在我脑中只有做题的步骤，没有`how``what``why`的头脑风暴，我在了解其他领域之际可以将它们看作新一门课程，抱着实用性和可理解性有目的的去理解这些东西，哪怕重新学习，哪怕找资料，我依旧认为我学习的才是最为纯粹的知识，我可以很自豪的说这门课程主要解决什么问题，这门课程核心思想是什么



所以，什么是操作系统 ？



在我学习了一段时间之后，现在深入认真学习操作系统的时候就会发现操作系统很难去完全定义，很难去滴水不漏的定义一个操作系统的真正定义，所以，这里会大致说一句什么是操作系统，在后期学习的过程之中会慢慢接触到操作系统的全貌

操作系统：先给一个笼统的定义，在我认为所有能处理程序的系统它都是操作系统，就比如，`RT-Thread`是操作系统，`windows`是操作系统，`linux`是操作系统。在调度硬件层面连接软件的界面都可以说是操作系统

![](/home/plote/图片/computer-hw-sw.png)

亦或者，我可以用`rcore`的教科书中的解释：

**操作系统这个系统软件干的事主要有两件：一是向下管理并控制计算机硬件和各种外设，二是向上管理应用软件并提供各种服务**

操作系统是一种系统软件，主要功能是向下管理CPU、内存和各种外设等硬件资源，并形成软件执行环境来向上管理和服务应用软件。这样的描述也符合大多数操作系统教材上对操作系统的定义。为了完成这些工作，操作系统需要知道如何与硬件打交道，如何给应用软件提供服务。这就有一系列与操作系统相关的理论、抽象、设计等来支持如何做和做得好这两件事情。

**只不过我认为所有讲述操作系统定义的必定离不开讲述历史，如果不谈论历史，真不能叫做一本好书或者好课**

## 站在时间长河看操作系统

### 20世纪初（1946.2.14图灵机诞生）

在1946 年出现电子计算机的时候，只有人类操作员（Operator）来管理和操作机器，还没有操作系统（Operating System）这种事物 。启动，扳开关，装卡片/纸带等比较辛苦的工作都是计算机操作员或者用户自己完成。操作员/用户带着记录有程序和数据的卡片 (Punch Card) 或打孔纸带去操作计算机。装好卡片/纸带后，启动卡片/纸带阅读器，把程序和数据读入计算机内存中之后，计算机就开始工作，并把结果也输出到卡片/纸带或显示屏上，最后程序停止

在那个时候的计算机硬件，就是一堆真空电子管，而操作员需要像高考填写答题卡那样涂写或者挖孔来处理计算机

不禁想一想，那时候，计算机刚出来之初，会有操作系统吗？

没有

能活着已经很厉害了



### 1950s的计算机

随着程序设计语言和编译技术的进步，推动了程序员开发翻译符号程序（即编译器）来自动把代码转换成机器代码，代替了以前低效的手工机器编码的方式，提高了程序开发的效率。但程序执行的效率还很低。而且随着计算机和 I/O 设备变得更强大，程序运行的时间减少了，相比之下，让计算机运行的准备时间变得更长了，使得计算机的整体执行效率很低

`Fortran`应运而生

```
C---- THIS PROGRAM READS INPUT FROM THE CARD READER,
C---- 3 INTEGERS IN EACH CARD, CALCULATE AND OUTPUT
C---- THE SUM OF THEM.
  100 READ(5,10) I1, I2, I3
   10 FORMAT(3I5)
      IF (I1.EQ.0 .AND. I2.EQ.0 .AND. I3.EQ.0) GOTO 200
      ISUM = I1 + I2 + I3
      WRITE(6,20) I1, I2, I3, ISUM
   20 FORMAT(7HSUM OF , I5, 2H, , I5, 5H AND , I5,
     *   4H IS , I6)
      GOTO 100
  200 STOP
      END
```

可以去问chat解释，但是也没有必要，在那个时候计算机才开始进入高速发展时期

在那个时候计算机比较少，而使用计算机的地方非常之多，所以很多地方都要使用计算机，每组需要计算机的人将卡带传递给计算机，计算机需要判断所工作的时间，而这时候就会发现CPU 大部分时间都在等待人类操作员的缓慢操作。由于过低的人工操作效率浪费了计算机的宝贵机时，所以就引入**监控程序（Monitor）辅助完成输入、输出、加载、运行程序等工作，多用户轮流共享计算机，operator 负责调度**从而提高了使用计算机的效率

而写程序 (戳纸带)、跑程序都是非常费事的，所以也有了库函数 + 管理程序排队运行的调度代码

这时候才开始引入操作系统：**操作 (operate) 任务 (jobs) 的系统 (system）**

在计算机执行打印任务时候，cpu可以调度切换到下一组想使用计算机的卡带，去处理它们的任务，就不用等待不需要的操作了

所以：“批处理系统” = 程序的自动切换 (换卡) + 库函数 API



批处理是指把一批作业（英文： **Job** ，古老的术语，可理解为现在的应用程序）以脱机方式（offline mode）输入到磁带上，并使这批作业能一个接一个地连续处理，流程如下：

1. 将磁带上的一个作业装入内存；
2. 操作系统把运行控制权交给该作业；
3. 当该作业处理完成后，控制权被交还给操作系统；
4. 重复 1-3 的步骤处理下一个作业直到所有作业处理完毕

### 10年后

1960年的时候，集成电路、总线出现，更快的速度，基本可以同时载入多个程序而不用 “换卡” 了，更加丰富的I/O设备，更加完善的中断/异常机制

在高速发展之后，CPU处理2个“卡带”，假如说其中A写飞了程序，弄出了野指针，刚好指向了B的内存管理之中，这时候B也=明明是好的也不能使用了

所以为防止程序之间形成干扰，操作系统自然地将共享资源 (如设备) 以 API 形式管理起来

出现了进程的概念：进程在执行 I/O 时，可以将 CPU 让给另一个进程，在多个地址空间隔离的程序之间切换，虚拟存储使一个程序出 bug 不会 crash 整个系统

有人提出想法：在某些时候，A程序卡了，它要是一直占用CPU，导致后面的B也运行不了，怎么解决这个问题？程序之间切换，为什么不让它们定时切换呢？

- Multics (MIT, 1965)：现代分时操作系统诞生



### 1970s+

集成电路空前发展，个人电脑兴起，“计算机” 已与今日无大异

CISC 指令集；中断、I/O、异常、MMU、网络、信号 API、管道 (对象)、grep (应用程序）…

已经是现在我们学习操作系统的模样了



### 现在

大数据、人工智能、机器学习、高速移动互联网络、AR/VR 对操作系统等系统软件带来了新的挑战。如何有效支持和利用这些技术是未来操作系统的方向。我们看到了华为逐步推出的 OpenHarmony 系统；小米也推出了物联网软件平台小米 Vela ；阿里推出了 AliOS Thing；腾讯推出了Tencent OS；苹果公司接连推出 A14、M1 等基于 ARM 的 CPU，逐步开始淘汰 X86 CPU；微软推出 Windows 10 IoT，Google 推出 Fuchsia OS。大家都在做着各种位于云、边、端操作系统的技术调整和创新，构建多种形态的网络基础设施。可以发现操作系统的外延在放大，位于云、边、端的操作系统通过多种形态的网络基础设施，跳出了传统单机为主的运行模式，支持应用程序在分布式环境下的互联、互通以及互操作，从而进一步延伸为分布式操作系统。

通过 “虚拟化” 硬件资源为程序运行提供服务的软件

- 更复杂的处理器和内存
  - 非对称多处理器 (ARM big.LITTLE; Intel P/E-cores)
  - Non-uniform Memory Access (NUMA)
  - 更多的硬件机制 Intel-VT/AMD-V, TrustZone/~~SGX~~, TSX, ...
- 更多的设备和资源
  - 网卡、SSD、GPU、FPGA...
- 复杂的应用需求和应用环境
  - 服务器、个人电脑、智能手机、手表、手环、IoT/微控制器……



操作系统在进步，学习操作系统的眼光和能力也要进步，善用书籍，善用工具，我依旧相信计算机行业正值风口，需要建设
